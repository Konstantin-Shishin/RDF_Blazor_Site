20151101 13:31
Мысли постоянно возвращаются к сервису, который можно было бы сделать и использовать в разных случаях. 
Мне все время хочется фиксировать информацию, нужен удобный интерфейс к "правильному" хранилищу. Уже
зафиксировано то, что есть кассеты и есть хранилище. Рассмотрим эту модель в развитии действий во времени,
в коллективе и в пространстве. Рассмотрим как можно не выключая и не переконфигурируя сохранять динамику
пополнения и использования данных. 

Пусть есть простой (примитивный) случай: есть один человек, одна тема и один сервис. К сервису мы прикрепляем
хранилище, построенное на нескольких кассетах. Пусть есть кассета, которая уже стабильная (не изменяется) и 
"рабочая" кассета, в которой накапливается информация. Информация - это мульти-медиа файлы, это записи базы 
данных, это ссылки на документы, опубликованные в интернете. Для одного пользователя даже авторизация не 
нужна. Нужна актуализация введенной информации. То есть, ввел информацию и через малое время, информация уже
появляется в интерфейсе. Сейчас это сделано для ввода данных, но не сделано для документов. Рассмотрим эту
ситуацию подробнее. Введен один документ, при вводе (возможно) указана коллекция, в которую документ попадает 
"по умолчанию". Коллекция уже существует. Документ обрабатывается и помещается в какое-то место в кассету и,
после того, как вычисляются и помещаются в кассету его интернет-варианты, документ доступен для просмотра
через полученный URI. То есть, проблемы актуализации информации при размещении документа в кассете не видно. 

Что изменится при наличии многих пользователей? Для редактирования базы данных, все уже предусмотрено в 
схеме: по идентификатору пользователя ищется fog-документ, владельцем которого является этот пользователь. 
И чтобы этот fog-документ позволял редактирование. А вот что делать с документами? Похоже, контент документов
нужно "отправлять" также в "авторские группы". Проблема в том, что документы располагаются по кассетам. Кассеты
имеют "представительство" в базе данных. Но, к сожалению, у этих документов нет информации о владельце. А может,
это и правильно. Но определить в какую кассету надо помещать документ - затруднительно. Можно, например, помещать
в кассету, в которой находится редактируемый данным пользователем fog-документ. Возможно, это выход...

20151107 13:28
День 7-е ноября - красный день календаря!

Довольно много думал о кассетах, о правильном их устройстве, о миграции решений. Вот какие мысли "бродят":
Хорошо бы напрямую обеспечивать эволюционный процесс изменений в структуре и интерфейсе кассет. Можно предложить
следующий подход. Есть абстрактый класс "кассета", есть его реализация. Со временем могут приходить другие идеи
и другие технологии. Тогда реализация кассеты изменяется. Кроме того, может меняться и интерфейс этого пакета.
Кроме того, уже созданные кассеты должны быть вовлекаемыми в обработку. Для этого можно предполагать наличие адаптера 
старой структуры к новому интерфейсу и конвертера для переделывания содержимого кассеты в новую структуру и 
придания ей нового интерфейса. Теретически возможно одноуровнемая схема с конвертером, но не думаю, что она практична. 

Еще я думал о таблице отождествления (или замен/уничтожений). Вспомнилось, что я хотел ориентироваться на "небольшую"
таблицу, чтобы технически проще было использовать оперативную память. 

Третий момент, который я еще не обсуждал - использование Поляра в кассетах. Думаю, что уже пора. Некоторые вопросы 
будут решаться по другому. Например - файло-директорые образования и их файловые сборки. Я там "выдумал" некоторую 
конструкцию. А ныне правильнее было бы использовать поляровскую ячейку. 

Вернемся к кассетам. Пусть есть T - класс, соответствующий (абстрактному) пониманию кассеты. T - это, в том числе, и
структура файлов, входящих в кассету. Но T - еще и совокупность методов по работе с кассетой. Методы по работе
разделяются на два множества Cr и Use, первое множество - метод, связанные с созданием кассеты, Use - с использонием
кассеты. Допустим, мы придумали новую структуру кассеты T1. Соответственно, для T1 реализуются свои методы. Если для T1
определить методы Use, то кассету можно использовать в "старых" системах. Но это неинтересно. Нам хочется старые кассеты
использовать в новых системах. Для этого надо создать "обертку" Wr для T такую, что обертка воспроизводит Use1 средствами 
Use. И также надо создать программный конвертер T -> T1. Вот как-то так... 

Соответственно, когда набор кассет состоит из кассет разных типов, мы должны анализировать тип кассеты и подбирать для 
него соответствующие резализации методов. В техническом плане можно определить кассету как абстрактный класс. 
Генератором значения конкретного класса для него будет статический метод, возможно с параметром - идентификатором или 
версией класса, по которому создавалась кассета. Дальше обработчик найдет конкретный класс или обертку и специализация
будет произведена. Посмотрю в код...

Все это не доделано и надо вернуться к этим вопросам.  

20151108 10:31
Теперь я задумался над семантикой RDF и редактирования RDF. Похоже ключевая причина семантических проблем, связанных
(у меня) с редактированием RDF в желании сохранить выжную роль за RDF-документами. Действительно, если рассматривать
RDF-базу данных как некоторое хранилище триплетов, обладающее определенными свойствами, то особых проблем нет. Можно
добавлять триплеты, можно убавлять триплеты (по шаблону или по одиночке). Логика редактирования достаточно легко
воспроизводится. Кажется есть некоторые (и возможно большие!) трудности в установлении эквивалентности (SameAs и др.),
в части наследования свойств и аналогичных вопросах. В базовом варианте, все аналогично системам реляционных таблиц. 
Там также ключевой является база данных, а способ изображения БД в текстовом виде (напр. CSV, TSV), применяется для 
технических действий и не рассматривается формой существования базы данных.  

Но если считать, что накапливание базы данных происходит в RDF-документах, то возникают проблемы.
Кажется главная проблема в том как "уничтожать" триплеты. Уничтожение или его аналог требуется при выполнении команд 
Sparql типа DELETE и при замене одних триплетов другими, что можно считать синтетически действием, состоящим из 
уничтожения и добавления. Действительно, как найти в тексте RDF-документов, неважно в каком формате, строчки или
фрагменты уничтожаемых триплетов? Если говорить о оперативной динамике изменения базы данных, то видимо - никак.

Остается отмечать это действие и выполнять при новом формировании оперативной базы данных. Для этого (мною) введены
операторы delete и substitute. Появилось понятие цепочки переименований. Появились проблемы, с этим свзязанные и
неудобства. Проблема заключается в том, что при выпадании отдельных звеньев из цепочки, она может распадаться на 
незовисимые определения одного и того же. Более того, уничтожение одного из вариантов, произведенное оператором по 
естественной логике, может привести к уничтожению сущности при восстановлении ранее "утеренной" связи substutute.
Неудобство заключается в том, что почти все определения, заполняемые вручную, напр. персон или организаций, 
переопределяются по нескольку раз. 

Для частичного решения этих затруднений, (мною) было предложено ввести временную отметку в определения записей. И
считать оригиналом запись с самой поздней отметкой. 

В семантику работы с RDF базой данных, "вклинилось" также желание разделить редактирующих пользователей по разным 
документам. Это позволяет следить за изменениями, вносимыми конкретным пользователем и, если надо, ликвидировать 
изменения "оптом" ликвидируя пользвоательский RDF-документ. Это также привнесло некоторые изменения в конструкции
RDF-документа, в которую был добавлен атрибут owner с указанием имени владельца. Еще парочка атрибутов prefix и
counter добавлена для целей контроля за порождаемыми именами. При этом, очередное "свободное" имя делается как 
конкатенация значений prefix и counter, а после порождения очередного имени, counter инкрементируется. Эта же пара
используется для защиты RDF-документа от изменений. Если отсутствует counter, то генерироваться имена не могут и 
добавление данных в документ блокируется. Эти "штучки" не очевидны, не знаю как к ним относиться.

Более или менее очевидными являются delete, substitute, временная отметка mT, owner.

Рассмотрим то, как это все работает. Причем семантика хранилища триплетов (по-возможности) будет "классическая".
Кроме хранилища будет множество RDF-документов и, кажется, дополнительная стуктура для поддержки процессов
редактирования.

20151112 12:47
20151113 20:05
Некоторое время занимался идеальными хеш-функциями. Сергей нашел любопытное решение, постарался разобраться. Вроде
понял. Хотя и не все. Задумался над разными видами кодирования. Можно кодировать в подряд идущие целые. Можно -
просто в целые. Или как-то промежуточно. Первый вид кодирования применим непосредственно, через построение массива
с доступом по целочесленному индексу. Второй - дает просто кодирование и дальше с этим что-то нужно делать. Например,
сортировать или выстраивать новый хеш. 

20151114 08:46
Из того, что я не понял в графовом методе построения идеальной хеш-функции, это вероятность появления циклов в графе. 
С другой стороны, есть идея как в один проход решать вопрос с зацикленностью графа. Дело в том, что слабая динамика
этого процесса кодирования скорее всего будет реализовываться через дополнительный хеш-словарь string -> int, 
располагаемый в оперативной памяти. Так вот, его можно начать формировать еще на стадии вычисления идеальной 
хеш-функции. Выявляя циклы, мы отбрасываем узлы, содержащие одну дугу. Все отбросили - в остальных есть циклы. 
Теперь убираем любое ребро именно в этот словарь. Даже номер можно сохранить. Или как-то по-другому. После "разрыва"
цикла, продолжаем отбрасывать узды до тех пор, пока не останется узлов или снова выявится цикл.

А как анализ и синтез графа выполнять на ячейках? Пусть есть множество (строковых) ключей объема n. Делаем массив для 
узлов. Размером mn. И есть две hash-функции f1, f2. Каждому ключу присвоим код в диапазоне 0..n-1. Дальше будем заполнять 
массив узлов. Перебираем ключи, вычисляем для каждого h1, h2. Хеш-значения используем как индекс(ы) в массиве узлов. И в 
узел добавим данный код ключа. Таким образом, узлы будут накапливать списки (кодов) ключей, с которыми они сопряжены. 
Очевидно, надо контролировать и рассмотривать особо ситуации, когда h1 = h2. Кроме того, надо h1 и h2 записать в 
информационном поле записи о ключе. 

Следующий этап - поиск циклов. Начинаем перебирать узлы и если в узле только один ключ, то узел "уничтожаем". Такой алгоритм
выглядит квадратичным, думаю, его можно сделать линейным. 

Допустим, циклов в графе не найдено. Начинаем выполнять разметку узлов. Берем узел, у которого только один ключ 
находится в его списке, пусть это будет h1. Присваиваем ему значение v1, напр. 0. 

Пусть (псевдо-)функция ind(key) обозначает индекс ключа key в массиве arcs, т.е. arcs[ind].k = key.   
Обозначения nd массив узлов размером mn. Узел может быть "пустым" или иметь значение. nd[ind] - выборка узла по индексу
Мы хотим обиспечить свойство:
ind(key) = (nd[f1(key)].v + nd[f2(key)].v) mod n

Если мы знаем ind[key] и одно из значений, напр. связанное с f1, то вычисляется и второе значение:
nd[f2(key)].v = (ind - nd[f1(key)].v) mod n

Получается, что массив узлов будет заполняться по мере перехода от одного ключа к другому. И так по мере обработки связной
части графа. Потом можно начать с новой точки. И с нового значения v1. Цикл в графе будет выражаться или в том, что не 
находится первая дуга. Или в том, что индекс в левой части присваивания f2(key), будет повторным, т.е. его значение уже 
заполнялось. 

Рассмотрим переход к следующему ключу. Мы вычислили значение узла, "придя" в него из ключа key_last. В списке (кодов) ключей,
который имеется в узле, надо убрать key_last и "пустить волну" из всех оставшихся ключей. Или пойти по первому попавшемуся, 
исключая ключи из спика по одному. 

Таким образом, мы будем двигаться от узла к узлу. узел + ключ, который условно уже обработан -> смотрим в ключ, находим 
парный узел, вычисляем его значение, можно рекурсивно начинать обработку новых пар. 

Может попробовать?..

Похоже, без сортировки не обойтись. Хотя если использовать ячейки фиксированного формата, то может быть... Действительно,
заводим массивы
Edges = [s: string]; // Хеш-функции вычисляются по необходимости
Nodes = [v: int, list: [int]]; // список кодов (индексов) ключей таких, что одна из хеш-функций у них совпадает с индексом узла

Начинаем вычислять... Попробую сначала на Linq. Только пожалуй "пересяду" в решение Polar.

20151203 20:30
Петя просит ускориться. Рассмотрев вместе с ним задачу, было определено наиболее простое решение, которое
позволит продвинуться в задаче построения фактографического сервиса. Решение заключается в том, что есть
обычная конфигурация кассет, первично порожденных кассетным менеджером. И есть типовая ситуация запросов
к информационному графу и запросов к документам. Дальше можно будет продвинуться к редактированию базы 
данных. Следующим шагом будет добавление документов. А потом посмотрим...

20151205 11:28
С разных сторон изучал имеющееся демонстрационное веб-приложение. Кажется в принципе, годится.  
Попробую сформулировать предварительные спецификации сервиса.

1. Сервис работает как Web-приложение под протоколом http. Корректный http-запрос принимает, корректный
http-ответ порождает. Естественно, запросы идут от разных клиентов, соответственно, (пока) каждый запрос
независим от предыдущих и прямо не влияет на последующие. Косвенное влияние может быть по данным. Запрос
внес или изменил данные, в следующих запросах новые данные будут использоваться.
2. Для выполнений функций сервиса, у приложения имеется один или несколько входов. Принцип разбиения на
разные входы не понятен. Ранее, команды группировались по группам: поиск данных (доступ к данным, 
получение документов, редактирующие команды). 

Команды поиска/доступа
GetRecordById(string id, bool withinverse) с опцией выдачи обратных отношений
SearchByName(string searchstring, string type)
И форматный вывод
GetItemById(string id, XElement format)

Команды получения документов
GetDoc(string uri, string type, parameters) параметрами вывода был размер превьюшки

Команды редактирования
Edit(XElement operator, DateTime mT, string user)
где оператор может быть новой или редактируемой записью, оператором уничтожения, оператором переименования.

Как-то так...

Еще нужны запросы с "подтаскиванием" файлового контента, возможно нужны конфигурирующие действия. Нужны
команды загрузки, вычисления базы данных.

Еще нужна схема подготовки превьюшек.

Вроде все...

Для отладки и дополнительных возможностей, надо делать сервис таким, чтобы был более или менее нормальный
html-интерфейс. Это означает, что результат соответствующих запросов имеет интерпретацию в html-коде
и может демонстрироваться в браузере.

20151206 11:00
Такой способ ранее был опробован в следующием варианте: есть "стандартный" вход .../Portrait.cshtml?параметры
и есть "специальный" вход .../PortraitSpecial.cshtml?параметры. И они означают разное. Причем гиперссылки
оформляются как "?параметры" позволяет не выходить из пространства соответствующего представления. Правда
перейти в другое представление надо как-то "хитро", напр. выделяя из текущего имени сервиса концовку и
используя ее. Как-то не очень...

Альтернативно, надо устроить полный разбор приходящих в реквесте параметров. И каким-то параметром может 
быть вид вывода. Тогда можно весь сервис устроить на одном входе. Посмотрю гугл.

Начинаю новый проект FactographService. Там я создам сначала "умный" класс, который умеет все необходимое.
А потом сделаю сервис. Перееду со своим протоколом в другой проект.

20151213 09:44
Решил порассуждать об идее "Включи свою семью в Историю", предложенной Петей. В этом что-то есть...
Я и раньше задумывался о семейных архивах и их включения в общее информационное пространство. Но удачного
навания пока не было. Предложенное название также не слишком запоминается, но довольно верно отражает 
идею. Причем идея может и должна быть расширена типа "Включи X в Историю", где X - достаточно произвольный
социум. И даже отдельный документ, отдельная история, отдельный факт. 

Суть возможного решения может быть в том, что пользователь формирует электронный архив на базе своих 
документов и знаний о том, что он помнит. Или о том, что происходит, но предположительно станет существенной
частью Истории. Этот архив связывается с другими через объединение основной информации о людях, организациях, 
географических системах. Также существенными являются ссылки на уже опубликованные документы, включая 
мульти-медиа документы.

Но как это должно выглядеть при формировании и использовании? Документы, а может и куски информации, должны
иметь возможность быть отмечеными как "исторические". А дальше, они "поднимаются" по дереву разбиений. Чем
выше, тем значимей. Также существенным является число ссылок на информационный объект. Предположим, какой-то
документ является более значимым, чем частный архив. Его надо бы перевести в более высокий статус. Как это
можно сделать? Если речь идет о документе, схема выглядит следующей. Документ состоит из карточки документа 
и из файла с контентом. Есть id, есть uri. Сделать копию карточки в публичном пространстве - "плевое" дело. 
А вот Uri - это вопрос. Можно считать, что Uri не перемещаем и владелец документа продолжает владеть
им "вечно". А как же копии и превьюшки? Теоретически можно сделать полную копию с оригинала. Но Uri "плохо"
опубликованного документа - дело не очень надежное. В документе можно подменить Uri. Мы теряем владельца. 
Разве что явно пропишем владение в базе данных. Наверное так. 

Поговорил с Петей. Более четко структурировал мысль. Есть некоторая ключевая трудность. Попробую ее 
сформулировать. Пусть множество определений конкретного пользователя разбивается на приватные, публичные
и общественные. Публичными назовем те, которые автором допускаются для публикации, общественными назовем
те публичные, которые "оценены" обществом. Идея распределения определений по пространству заключается в
том, что пространство данных пользователя состоит из его приватных и его публичных данных и всех 
общественных. Причем он также имеет доступ к "чужим" публичным данным, но только через специфический сервис.
То есть, доступ к "чужой" публичной информациии осуществляется через сервис, динамически выполняющий данный
вид запросов. Соответственно, идентификаторы распадаются на разные пространства. Имея идентификатор, машина
базы данных сначала ищет с общественных данных, потом в своих приватных и публичных данных. Неудача поиска
может означать то, что это определение принадлежит чужому "домену". Но какому именно? Какому домену посылать 
запрос? Непонятно...

20151215 09:35
20-15, 12-15... Жалко нет 20-го месяца...

Я увидел в предыдущей задаче родственные мотивы с задачей слабой синхронизации, решаемой на дереве. 
Там также новое данное идет по дереву. А почему бы запросы на публичные, но не общественные данные, 
не посылать по тому же маршруту. Посылаем "всем", собираем получившийся результат. Это кажется громоздким,
но современная технология map-reduce работает похожим образом. Может, за такими технологиями будущее???

Детальнее. Формируем пакет с запросом. Типа "найти запись по идентификтору id". Посылаем запрос вверх по 
дереву. Если удалось найти такую запись, то другим пакетом (а может и этим), результат начинает возвращаться
маршрутом, каким пришел. Такой сокращенный вариант прохождения запроса вряд ли будет эффективным. Видится 
то, что обойти придется все узлы. Действительно, запись могла быть переопределена, а значит нахождение 
какой-то не гарантирует, что это оригинал. Кроме того, команда может быть в собирании расширенной записи, 
т.е. к записи мы хотим "приложить" список других записей, которые ссылаются на данную. Кстати, в этом может
быть вопрос... Вопрос как раз в том, как собирать обратные ссылки в условиях возможностей достаточно 
кардинального переопределения записи в других местах. Вроде брезжит решение, заключающееся в том, что в 
список обратных ссылок помещаются пары: idi - идентификатор встреченной "обратной" записи, временная отметка
этой записи. Далее возникнут проблемы с уничтожением, потом с отождествлением. В общем - не соскучишься. 

Там есть вопрос о том, в какой мере надо использовать исходную базу данных, а в какой - техническую. Скорее
всего, надо работать с технической. Но все ли будет правильно решаться? Еще идея - в запросе указывать
формат и постепенно собирать дерево результата. Идея хорошая, но пока представление дерева запроса/результата 
выглядит слишком громозким.

Попробую сформулировать самую простую модель по распределенной синхронизации. Думаю, предложить ее Сергею
Лештаеву для обдумывания.

Пусть есть множество информационных баз, хранящих информацию вида идентифицированных айтемов. То есть,
информационая база (ИБ) состоиз из (конечного) неупорядоченного множества айтемов. Айтем, информационная
единица, состоящая из идентификатора и значения. Мы получили key-value storage. Ключи все разные. Все ИБ 
нашей модели имеют одинаковый набор айтемов. Теперь предположим появляется динамика. Каждая из ИБ начинает
изменяться. Изменения состоят из добавления, изменения (update) и уничтожения айтемов. Соответственно, 
изменения выполняются по командам, задаваемым непосредственно в ИБ. Эти команды: добавить айтем, изменить
айтем, уничтожить айтем. При добавлении, генерируются идентификаторы, не пересекающиеся с множеством 
использованных идентификаторов. Требуется организовать взаимодейстие между информационными базами такое, 
чтобы изменения были внесены не только в отдельные базы, но и распространились по всем и через какое-то 
время, чтобы все ИБ снова стали идентичными. 

20151216 08:29
Пока противоречий в заявленном (но не описанном!) подходе не выявлено. Есть некоторые проблемы с реализацией
форматного запроса. Было бы здорово, если бы он выполнялся за один обход дерева IB, но вроде на получается.



 



 

       







  
 






    
